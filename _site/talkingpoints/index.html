<!doctype html>
<html>
<head>
    <meta http-equiv="Content-type" content="text/html;charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="description" content="DoIIIT">
    <meta name="author" content="gparuthi">
    <link rel="alternate" type="application/rss+xml"  href="http://www.intecolab.com/feed.xml" title="Interaction Ecologies RSS Feed">

    <title>DoIIIT | Talking Points</title>

    <link rel="stylesheet" media="all" href="/css/mine.css" />
    <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    

    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

    <link href='http://fonts.googleapis.com/css?family=PT+Serif' rel='stylesheet' type='text/css'>

    <!-- foundation -->
    <script src="http://s.codepen.io/assets/libs/modernizr.js" type="text/javascript"></script>
    <link rel='stylesheet prefetch' href='http://cdn.foundation5.zurb.com/foundation.css'>
    <script src='http://cdn.foundation5.zurb.com/foundation.js'></script>

    

    <!-- Any other scripts or anything that the page may want. -->
    
    

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-55232947-1', 'auto');
      ga('send', 'pageview');

  </script>
</head>

<body lang="en">
    <div class="container">
        
        <div class="smaller_container">
            
            <div class="header">
                
                <p>
                    <a href="/" rel="author">
                        <i class="fa fa-th"></i>
                        DoIIIT
                    </a>
                </p>
                <h1><p>Talking Points</p>
</h1>
                
            </div>

            <div class="content">
                
                <aside>
                    Published 
                    <!--<br />
                    Reading time: Talking Points is collaborative student project at the University of Michigan whose aim is develop a prototype urban orientation and contextual information system. By using a mobile application to read Bluetooth tags or GPS coordinates positioned around a city, user generated location information is presented to the user via either an audio or visual modular interface. 


##Video

<iframe width="420" height="315" src="//www.youtube.com/embed/pU3uiOkjZ48" frameborder="0" allowfullscreen></iframe>
<br />
<br />

## Supporting Spatial Awareness and Independent Wayfinding for Pedestrians with Visual Impairments

Much of the information designed to help people navigate the
built environment is conveyed through visual channels, which
means it is not accessible to people with visual impairments. Due
to this limitation, travelers with visual impairments often have
difficulty navigating and discovering locations in unfamiliar
environments, which reduces their sense of independence with
respect to traveling by foot. In this paper, we examine how mobile
location-based computing systems can be used to increase the
feeling of independence in travelers with visual impairments. A
set of formative interviews with people with visual impairments
showed that increasing one’s general spatial awareness is the key
to greater independence. This insight guided the design of Talking
Points 3 (TP3), a mobile location-aware system for people with
visual impairments that seeks to increase the legibility of the
environment for its users in order to facilitate navigating to
desired locations, exploration, serendipitous discovery, and
improvisation. We conducted studies with eight legally blind
participants in three campus buildings in order to explore how and
to what extent TP3 helps promote spatial awareness for its users.
The results shed light on how TP3 helped users find destinations
in unfamiliar environments, but also allowed them to discover
new points of interest, improvise solutions to problems
encountered, develop personalized strategies for navigating, and,
in general, enjoy a greater sense of independence.


## Supporting visually impaired navigation: a needs-finding study.

Pablo-Alejandro Quinones, Tammy Greene, Rayoung Yang, and Mark Newman. 2011. Supporting visually impaired navigation: a needs-finding study. In CHI '11 Extended Abstracts on Human Factors in Computing Systems (CHI EA '11). ACM, New York, NY, USA, 1645-1650. [pdf](http://rayang.people.si.umich.edu/links/TalkingPoints-quinones.pdf)

In this paper, we investigate the requirements for designing
systems to support wayfinding for visually impaired
individuals. We report the results of an interview study with
20 individuals with visual impairments, asking about their
way-finding tools, techniques, and obstacles. Our findings
provide an account of the practices followed when navigating
familiar, unfamiliar, and dynamic environments, and common
breakdowns encountered during the wayfinding process. The
findings from this study suggest ways of implementing a
location-based system to assist in the recovery from various
obstacles.

{% include pubs.md %}


.-->
                </aside>
                <p>Talking Points is collaborative student project at the University of Michigan whose aim is develop a prototype urban orientation and contextual information system. By using a mobile application to read Bluetooth tags or GPS coordinates positioned around a city, user generated location information is presented to the user via either an audio or visual modular interface.</p>

<h2 id="video">Video</h2>

<iframe width="420" height="315" src="//www.youtube.com/embed/pU3uiOkjZ48" frameborder="0" allowfullscreen=""></iframe>
<p><br />
<br /></p>

<h2 id="supporting-spatial-awareness-and-independent-wayfinding-for-pedestrians-with-visual-impairments">Supporting Spatial Awareness and Independent Wayfinding for Pedestrians with Visual Impairments</h2>

<p>Much of the information designed to help people navigate the
built environment is conveyed through visual channels, which
means it is not accessible to people with visual impairments. Due
to this limitation, travelers with visual impairments often have
difficulty navigating and discovering locations in unfamiliar
environments, which reduces their sense of independence with
respect to traveling by foot. In this paper, we examine how mobile
location-based computing systems can be used to increase the
feeling of independence in travelers with visual impairments. A
set of formative interviews with people with visual impairments
showed that increasing one’s general spatial awareness is the key
to greater independence. This insight guided the design of Talking
Points 3 (TP3), a mobile location-aware system for people with
visual impairments that seeks to increase the legibility of the
environment for its users in order to facilitate navigating to
desired locations, exploration, serendipitous discovery, and
improvisation. We conducted studies with eight legally blind
participants in three campus buildings in order to explore how and
to what extent TP3 helps promote spatial awareness for its users.
The results shed light on how TP3 helped users find destinations
in unfamiliar environments, but also allowed them to discover
new points of interest, improvise solutions to problems
encountered, develop personalized strategies for navigating, and,
in general, enjoy a greater sense of independence.</p>

<h2 id="supporting-visually-impaired-navigation-a-needs-finding-study">Supporting visually impaired navigation: a needs-finding study.</h2>

<p>Pablo-Alejandro Quinones, Tammy Greene, Rayoung Yang, and Mark Newman. 2011. Supporting visually impaired navigation: a needs-finding study. In CHI ‘11 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‘11). ACM, New York, NY, USA, 1645-1650. <a href="http://rayang.people.si.umich.edu/links/TalkingPoints-quinones.pdf">pdf</a></p>

<p>In this paper, we investigate the requirements for designing
systems to support wayfinding for visually impaired
individuals. We report the results of an interview study with
20 individuals with visual impairments, asking about their
way-finding tools, techniques, and obstacles. Our findings
provide an account of the practices followed when navigating
familiar, unfamiliar, and dynamic environments, and common
breakdowns encountered during the wayfinding process. The
findings from this study suggest ways of implementing a
location-based system to assist in the recovery from various
obstacles.</p>

<h2 id="publications">Publications</h2>

<div class="publication">
    <div><img src="/images/projects/talking-points/tp4.jpg" width="180px" /></div>
    <div>
    	<p><strong>Supporting spatial awareness and independent wayfinding for pedestrians with visual impairments</strong>
    	<br />
    	<a href="http://rayang.people.si.umich.edu/">Rayoung Yang</a>,
Sangmi Park, 
Sonali R. Mishra, 
Zhenan Hong, 
Clint Newsom, 
Hyeon Joo, 
Erik Hofer,
<a href="http://mwnewman.people.si.umich.edu/">Mark Newman</a>

    	<br />
    	ASSETS 2011
    	<br />
    	<a href="http://rayang.people.si.umich.edu/links/Assets2011.pdf">pdf</a>
    	</p>
    </div>
</div>


                
            </div>

            

            <hr />
            <div class="footer"> | <a href="http://si.umich.edu">School of Information</a> | <a href="//www.umich.edu">University of Michigan</a></div>
        </div>
        
    </div>
    
</div>
</body>
</html>
